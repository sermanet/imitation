# Unsupervised Imitation Learning
Pierre Sermanet<sup>1</sup>\*, Corey Lynch<sup>1</sup>\*†, Yevgen Chebotar<sup>2</sup>\*, Kelvin Xu<sup>1</sup>†, Jasmine Hsu<sup>1</sup>, Eric Jang<sup>1</sup>, Stephan Schaal<sup>2</sup>, Sergey Levine<sup>1</sup><br>
<sup>1</sup> Google Brain, <sup>2</sup> University of Southern California<br>
(* equal contribution, † Google Brain Residency program [g.co/brainresidency](https://research.google.com/teams/brain/residency/))

#### Project

The general goal of this project is to give to robots the ability to learn to imitate humans without any supervision.<br>
We present the following papers as steps towards of that goal.

### [1. Time-Contrastive Networks ](https://sermanet.github.io/tcn/)

<img src='docs/figs/pose_squat.mov.gif' width='540'>

### [2. Unsupervised Perceptual Rewards ](https://sermanet.github.io/rewards/)

<img src='docs/figs/observation.gif' height='270'>  <img src='docs/figs/imitation.gif' height='270'>

### [3. Learning to imitate ](https://sermanet.github.io/imitate/)

<img src='docs/figs/kuka_pouring.mov.gif' height='270'>
